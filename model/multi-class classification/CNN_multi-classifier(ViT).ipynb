{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aNsvyyF-5jNJ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j92IpCmM5fne"},"outputs":[],"source":["from torchvision import utils\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0LF-aYC5kmt"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# Assuming that we are on a CUDA machine, this should print a CUDA device:\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V30Jbaih5oH2"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"He6IEFc75nVZ"},"outputs":[],"source":["path_train = '/content/drive/MyDrive/BME AI/CNN classification/data2/train/'\n","path_valid = '/content/drive/MyDrive/BME AI/CNN classification/data2/validation/'\n","path_test = '/content/drive/MyDrive/BME AI/CNN classification/data2/test/'"]},{"cell_type":"markdown","metadata":{"id":"sNuzeYKNBcf2"},"source":["## 영상데이터에 대한 전처리과정 정의하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BHa492f15tw4"},"outputs":[],"source":["train_transforms = transforms.Compose(\n","      [\n","          transforms.Grayscale(num_output_channels=3),\n","          transforms.Resize((224,224)),\n","          transforms.ToTensor(),\n","      ]\n","    )"]},{"cell_type":"markdown","metadata":{"id":"2m9b8wp3Bfm5"},"source":["## ImageFolder를 활용하여 data loader를 생성하기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qd4SJm_x5vYn"},"outputs":[],"source":["batch_size = 32\n","\n","trainset = torchvision.datasets.ImageFolder(root = path_train,transform=train_transforms)\n","validset = torchvision.datasets.ImageFolder(root = path_valid,transform=train_transforms)\n","testset = torchvision.datasets.ImageFolder(root = path_test,transform=train_transforms)\n","\n","trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True)\n","validloader = torch.utils.data.DataLoader(validset,batch_size=batch_size,shuffle=False)\n","testloader = torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"r4ORSvvq5wlo"},"outputs":[],"source":["tgtnames = trainset.classes\n","print(tgtnames)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1pT6xCLI5x76"},"outputs":[],"source":["print(len(trainset),len(validset), len(testset))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rY-MMaUi5y7i"},"outputs":[],"source":["for X, y in trainloader:\n","  print(X.shape)\n","  print(y.shape)\n","  I = X[0][0].numpy()\n","  plt.figure(dpi=128)\n","  plt.imshow(I,cmap='gray')\n","  plt.title(tgtnames[y[0]])\n","  plt.show()\n","  break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UZVgb8-IeLfX"},"outputs":[],"source":["pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r-iFjFX4CgAR"},"outputs":[],"source":["import timm\n","num_classes = 4\n","model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLIxcqp6ei6w"},"outputs":[],"source":["import torch.optim as optim\n","import torch.nn as nn\n","from torch.optim import lr_scheduler\n","\n","citerion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n","\n","num_epochs = 30  # 학습할 epoch 수입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gOaYz7WBhISh"},"outputs":[],"source":["## Adam optimizer\n","\n","# import torch.optim as optim\n","# import torch.nn as nn\n","# from torch.optim import lr_scheduler\n","\n","# criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.Adam(model.parameters(), lr=0.001)\n","# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYnJlVEX_v6d"},"outputs":[],"source":["# import torchsummary\n","\n","\n","# torchsummary.summary(model, (3,224,224))"]},{"cell_type":"markdown","metadata":{"id":"pWPDUKkIBs-Y"},"source":["## Model 학습 진행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TeY5ne0qhxEM"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hijCac8IWFg3"},"outputs":[],"source":["num_classes = 4  # 분류할 클래스의 개수입니다.\n","model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()  # 손실 함수로 CrossEntropyLoss를 사용합니다.\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # 최적화 알고리즘으로 SGD를 사용합니다.\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)  # learning rate를 조절하기 위한 스케줄러입니다.\n","\n","num_epochs = 30  # 학습할 epoch 수입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"j-WEmhUhTTVT"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","Train Loss: 0.7526 Acc: 0.6885\n","Valid Loss: 0.5543 Acc: 0.7544\n","Epoch 2/30\n","Train Loss: 0.2168 Acc: 0.9148\n","Valid Loss: 0.2466 Acc: 0.9298\n","Epoch 3/30\n","Train Loss: 0.0865 Acc: 0.9623\n","Valid Loss: 0.4688 Acc: 0.8947\n","Epoch 4/30\n","Train Loss: 0.0467 Acc: 0.9846\n","Valid Loss: 0.1700 Acc: 0.9123\n","Epoch 5/30\n","Train Loss: 0.0230 Acc: 0.9930\n","Valid Loss: 0.1560 Acc: 0.9474\n","Epoch 6/30\n","Train Loss: 0.0237 Acc: 0.9958\n","Valid Loss: 0.3036 Acc: 0.9211\n","Epoch 7/30\n","Train Loss: 0.0057 Acc: 0.9986\n","Valid Loss: 0.1653 Acc: 0.9561\n","Epoch 8/30\n","Train Loss: 0.0015 Acc: 1.0000\n","Valid Loss: 0.1566 Acc: 0.9561\n","Epoch 9/30\n","Train Loss: 0.0009 Acc: 1.0000\n","Valid Loss: 0.1492 Acc: 0.9561\n","Epoch 10/30\n","Train Loss: 0.0007 Acc: 1.0000\n","Valid Loss: 0.1446 Acc: 0.9561\n","Epoch 11/30\n","Train Loss: 0.0006 Acc: 1.0000\n","Valid Loss: 0.1420 Acc: 0.9561\n","Epoch 12/30\n","Train Loss: 0.0006 Acc: 1.0000\n","Valid Loss: 0.1394 Acc: 0.9561\n","Epoch 13/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1375 Acc: 0.9561\n","Epoch 14/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1356 Acc: 0.9649\n","Epoch 15/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1355 Acc: 0.9649\n","Epoch 16/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1354 Acc: 0.9649\n","Epoch 17/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1352 Acc: 0.9649\n","Epoch 18/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1351 Acc: 0.9649\n","Epoch 19/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1350 Acc: 0.9649\n","Epoch 20/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1349 Acc: 0.9649\n","Epoch 21/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1348 Acc: 0.9649\n","Epoch 22/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1348 Acc: 0.9649\n","Epoch 23/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1348 Acc: 0.9649\n","Epoch 24/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1348 Acc: 0.9649\n","Epoch 25/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1348 Acc: 0.9649\n","Epoch 26/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1348 Acc: 0.9649\n","Epoch 27/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1347 Acc: 0.9649\n","Epoch 28/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1347 Acc: 0.9649\n","Epoch 29/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1347 Acc: 0.9649\n","Epoch 30/30\n","Train Loss: 0.0005 Acc: 1.0000\n","Valid Loss: 0.1347 Acc: 0.9649\n","Training complete.\n"]}],"source":["# 모델 학습\n","\n","loss_train = []\n","accs_train = []\n","accs_valid = []\n","accs_test = []\n","\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","    # print(\"-\" * 10)\n","    \n","    # 학습 모드로 설정\n","    model.train()\n","    \n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    \n","    for images, labels in trainloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # 그래디언트 초기화\n","        optimizer.zero_grad()\n","        \n","        # 순전파\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # 역전파 + 최적화\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # 통계\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    \n","    # 에폭별 학습 결과 출력\n","    epoch_loss = running_loss / len(trainset)\n","    epoch_acc = correct / total\n","    loss_train.append(epoch_loss)\n","    accs_train.append(epoch_acc)\n","    print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n","\n","    \n","    # 검증 모드로 설정\n","    model.eval()\n","    \n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    \n","    with torch.no_grad():\n","        for images, labels in validloader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            \n","            # 순전파\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            \n","            # 통계\n","            running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    \n","    # 에폭별 검증 결과 출력\n","    epoch_loss = running_loss / len(validset)\n","    epoch_acc = correct / total\n","    accs_valid.append(epoch_acc)\n","    print(f\"Valid Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n","    \n","    # learning rate 갱신\n","    scheduler.step()\n","\n","print(\"Training complete.\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GVLKIdEMXEGl"},"outputs":[],"source":["model.eval()\n","\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for images, labels in testloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","            \n","        # 순전파\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","            \n","        # 통계\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","# 테스트 정확도 출력\n","epoch_acc = correct / total\n","accs_test.append(epoch_acc)  # 테스트 정확도 추가\n","print(f\"Test Accuracy: {epoch_acc:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a1OYltcmc9LG"},"outputs":[],"source":["print(\"Training Loss:\", loss_train)\n","print(\"Training Accuracy:\", accs_train)\n","print(\"Validation Accuracy:\", accs_valid)\n","print(\"Test Accuracy:\", accs_test)"]},{"cell_type":"markdown","metadata":{"id":"WZ-cm0bRBvzf"},"source":["## 학습과정의 요약"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eUrUzHrF0aim"},"outputs":[],"source":["plt.figure(2,dpi=80)\n","plt.subplot(121)\n","plt.plot(loss_train,label='train loss')\n","plt.legend(loc='upper right')\n","plt.subplot(122)\n","plt.plot(accs_train,label='train accuracy')\n","plt.plot(accs_valid,label='valid accuracy')\n","# plt.plot(accs_test, label='test accuracy')\n","plt.legend(loc='lower right')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"VIAnu7ZJByeS"},"source":["## Validation set에 대한 개별결과 확인 (Inference)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwCA-h_n9YrD"},"outputs":[],"source":["from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nve8tPhP9Zd2"},"outputs":[],"source":["N = 51\n","#validset.imgs[N][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7RdeCbIs9acF"},"outputs":[],"source":["I = Image.open(validset.imgs[N][0])\n","X = train_transforms(I)\n","y = validset.targets[N]\n","\n","print(tgtnames[y])\n","I\n"]},{"cell_type":"markdown","metadata":{"id":"cJSNUGyEB0hM"},"source":["## Validation set에 대한 결과 요약하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OtCNtqCW9cxC"},"outputs":[],"source":["y_list = np.array([])\n","y_hat_list = np.array([])\n","for X,y in validloader:\n","  y_hat = model(X.to(device))    \n","  y_hat = y_hat.argmax(dim=1)\n","  y_list = np.append(y_list,y)\n","  y_hat_list = np.append(y_hat_list,y_hat.cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJZ2U_MS9dr5"},"outputs":[],"source":["from sklearn.metrics import (\n","    classification_report, confusion_matrix,\n","    ConfusionMatrixDisplay\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQS16OYl9esq"},"outputs":[],"source":["print(classification_report(\n","    y_list,\n","    y_hat_list,\n","    target_names=tgtnames))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OFr1GVak9gFC"},"outputs":[],"source":["cm = confusion_matrix(\n","    y_list,\n","    y_hat_list,\n","#    normalize='true',\n",")\n","disp = ConfusionMatrixDisplay(\n","    confusion_matrix=cm,\n","    display_labels=tgtnames,\n",")\n","disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1])"]},{"cell_type":"markdown","metadata":{"id":"l1nQygAnbZCZ"},"source":["## Test set에 대한 결과 요약하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YhIIQ-rxbYpz"},"outputs":[],"source":["y_list = np.array([])\n","y_hat_list = np.array([])\n","for X,y in testloader:\n","  y_hat = model(X.to(device))    \n","  y_hat = y_hat.argmax(dim=1)\n","  y_list = np.append(y_list,y)\n","  y_hat_list = np.append(y_hat_list,y_hat.cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2P8Isthubefs"},"outputs":[],"source":["from sklearn.metrics import (\n","    classification_report, confusion_matrix,\n","    ConfusionMatrixDisplay\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2P6sGIebfsM"},"outputs":[],"source":["print(classification_report(\n","    y_list,\n","    y_hat_list,\n","    target_names=tgtnames))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SoRRaMgTbhV8"},"outputs":[],"source":["cm = confusion_matrix(\n","    y_list,\n","    y_hat_list,\n","#    normalize='true',\n",")\n","disp = ConfusionMatrixDisplay(\n","    confusion_matrix=cm,\n","    display_labels=tgtnames,\n",")\n","disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x-LrQ3Wnbooo"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}